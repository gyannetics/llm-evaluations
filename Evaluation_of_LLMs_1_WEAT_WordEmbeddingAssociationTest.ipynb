{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNiwA+S9MxPrjhB/y9qxJeV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gyannetics/llm-evaluations/blob/main/Evaluation_of_LLMs_1_WEAT_WordEmbeddingAssociationTest.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation of LLMs : 1. WEAT - WordEmbeddingAssociationTest"
      ],
      "metadata": {
        "id": "ngyVI0XEfWTG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ypaANm-Yd-Rk"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# We are trying to find the association between Professions and Genders and identify if there us any bias"
      ],
      "metadata": {
        "id": "zoDi5En9rkaZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = ['doctor', 'engineer', 'scientist'] # TargetSet 1\n",
        "Y = ['nurse', 'teacher', 'receptionist'] # TargetSet 2\n",
        "\n",
        "# Gender Specific Attribute Sets\n",
        "A = ['man', 'male'] # AttributeSet 1\n",
        "B = ['woman', 'female'] # Attribute Set2"
      ],
      "metadata": {
        "id": "PwzSaf0GkmTR"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer, BertModel\n",
        "import torch\n",
        "\n",
        "# Initialize the tokenizer and model\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Function to generate embeddings\n",
        "def get_embeddings(word_list):\n",
        "    embeddings_dict = {}\n",
        "    with torch.no_grad():  # No need to calculate gradients\n",
        "        for word in word_list:\n",
        "            inputs = tokenizer(word, return_tensors=\"pt\")\n",
        "            outputs = model(**inputs)\n",
        "            # Take the embeddings from the last hidden state\n",
        "            # The shape is [batch_size, sequence_length, hidden_size]\n",
        "            # We take the mean of the sequence_length dimension to get a single vector\n",
        "            embeddings = outputs.last_hidden_state.mean(dim=1)\n",
        "            embeddings_dict[word] = embeddings\n",
        "    return embeddings_dict\n",
        "\n",
        "# Combine your lists\n",
        "words = ['doctor', 'engineer', 'scientist', 'nurse', 'teacher', 'receptionist', 'man', 'male',  'woman', 'female']\n",
        "\n",
        "# Get embeddings\n",
        "embeddings = get_embeddings(words)\n",
        "\n",
        "# Print the shape of the embedding for the first word to verify\n",
        "print(f\"Shape of '{words[0]}' embedding:\", embeddings[words[0]].shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uVY73f5qmkL0",
        "outputId": "9338f2cd-3a78-4928-9e47-8f5d2b2a774f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of 'doctor' embedding: torch.Size([1, 768])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: create word embeddings to the above items in the lists and return them as a dictionary for each item in the list\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "def create_word_embeddings(X, Y, A, B):\n",
        "  # Concatenate all the lists into a single list\n",
        "  all_words = X + Y + A + B\n",
        "\n",
        "  # Create a dictionary to store the word embeddings\n",
        "  word_embeddings = {}\n",
        "\n",
        "  # Iterate over the list of words and create a random embedding for each word\n",
        "  for word in all_words:\n",
        "    word_embeddings[word] = np.random.rand(10)  # Replace 100 with the desired embedding dimension\n",
        "\n",
        "  return word_embeddings\n",
        "\n",
        "# Call the function to create word embeddings\n",
        "word_embeddings = create_word_embeddings(X, Y, A, B)\n",
        "\n",
        "# Print the word embeddings\n",
        "print(word_embeddings)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VwAI4lQJlZYc",
        "outputId": "8e34c6c2-39f9-4d49-9c05-91356646b865"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'doctor': array([0.20775136, 0.84769692, 0.23346669, 0.77797114, 0.64938575,\n",
            "       0.62109598, 0.02598373, 0.78171709, 0.06262078, 0.62742006]), 'engineer': array([0.05914125, 0.49459845, 0.08427656, 0.58388544, 0.09980845,\n",
            "       0.59715969, 0.36476647, 0.0372791 , 0.4569011 , 0.22430984]), 'scientist': array([0.51448205, 0.47207151, 0.5166217 , 0.85510807, 0.45523899,\n",
            "       0.72229528, 0.11633141, 0.81926343, 0.10807944, 0.37482172]), 'nurse': array([0.66064657, 0.98340902, 0.76074813, 0.6823608 , 0.01934922,\n",
            "       0.6473569 , 0.79191913, 0.96181932, 0.36293627, 0.87350419]), 'teacher': array([0.20243003, 0.78632863, 0.49297467, 0.07464676, 0.85823365,\n",
            "       0.07124516, 0.34884318, 0.51810275, 0.48282992, 0.20317198]), 'receptionist': array([0.54442437, 0.99420296, 0.5121149 , 0.84854754, 0.565648  ,\n",
            "       0.96696614, 0.90646459, 0.68113484, 0.13411828, 0.08918251]), 'man': array([0.47451315, 0.12558826, 0.17568515, 0.13052301, 0.06955689,\n",
            "       0.27641262, 0.88921514, 0.50854963, 0.5932961 , 0.91019896]), 'male': array([0.39527318, 0.38632544, 0.98236338, 0.97580643, 0.85376476,\n",
            "       0.33692091, 0.89282073, 0.40841916, 0.37423002, 0.33994951]), 'boy': array([0.94320979, 0.13026715, 0.77741863, 0.24985046, 0.8611145 ,\n",
            "       0.59427926, 0.73432906, 0.33890891, 0.11079224, 0.14836814]), 'woman': array([0.42682865, 0.97066429, 0.6089043 , 0.20585717, 0.87631782,\n",
            "       0.99696997, 0.72430289, 0.50088504, 0.94454904, 0.90019955]), 'female': array([0.11113117, 0.19680063, 0.51501734, 0.49064261, 0.0260307 ,\n",
            "       0.78096214, 0.14559456, 0.70336634, 0.64503716, 0.40961171]), 'girl': array([0.01341021, 0.43927789, 0.24765758, 0.53096633, 0.83097012,\n",
            "       0.69552865, 0.19527556, 0.06794882, 0.21279889, 0.74289499])}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity"
      ],
      "metadata": {
        "id": "rF2EC9hTnCuZ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_embeddings = embeddings.copy()"
      ],
      "metadata": {
        "id": "oWCZSM_UnU-9"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def s(w, X, Y):\n",
        "  sim_X = np.mean([cosine_similarity(word_embeddings[w].reshape(1,-1), word_embeddings[x].reshape(1,-1)) for x in X])\n",
        "  sim_Y = np.mean([cosine_similarity(word_embeddings[w].reshape(1,-1), word_embeddings[y].reshape(1,-1)) for y in Y])\n",
        "  return sim_X - sim_Y"
      ],
      "metadata": {
        "id": "jtKV8KQOnJKd"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weat_score = sum([s(a, X, Y) for a in A]) - sum([s(b, X, Y) for b in B])"
      ],
      "metadata": {
        "id": "_HOAYQVcoem7"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weat_score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L1l6_hlJpDWQ",
        "outputId": "e42cfa50-9a46-40cd-8257-721fab168943"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.017807185649871826"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TCwJiWRRpU4w"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}